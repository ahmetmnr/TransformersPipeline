# -*- coding: utf-8 -*-
"""
Transformers KÃ¼tÃ¼phanesi - Modern Pipeline Demo ArayÃ¼zÃ¼ (Optimize EdilmiÅŸ)
"""

import gradio as gr
from transformers import pipeline, AutoProcessor, AutoModelForVision2Seq, AutoModelForCausalLM, AutoTokenizer
import torch
import gc
from PIL import Image
import requests
from io import BytesIO
import numpy as np
from sentence_transformers import SentenceTransformer, util
import base64
import soundfile as sf

# GPU kullanÄ±mÄ± iÃ§in device deÄŸiÅŸkeni
device = 0 if torch.cuda.is_available() else -1

# Daha basit CSS - sadece gerekli stiller
css = """
.result-card {
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    margin-bottom: 1rem;
    overflow: hidden;
}
.result-header {
    padding: 0.75rem;
    color: white;
    font-weight: bold;
}
.sentiment-positive { background-color: #22c55e; }
.sentiment-negative { background-color: #ef4444; }
.sentiment-neutral { background-color: #3b82f6; }
.result-content { padding: 0.75rem; }
"""

# Daha basit tema
theme = gr.themes.Soft(
    primary_hue="indigo",
    secondary_hue="blue"
)

# Modelleri Ã¶nbellekte tutan sÄ±nÄ±f
class PipelineCache:
    def __init__(self):
        self.pipelines = {}
    
    def get_pipeline(self, task, model=None, **kwargs):
        key = f"{task}_{model}" if model else task
        if key not in self.pipelines:
            # BelleÄŸi temizle
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
            # Pipeline oluÅŸtur
            self.pipelines[key] = pipeline(task, model=model, device=device, **kwargs)
        return self.pipelines[key]

# Pipeline Ã¶nbelleÄŸi oluÅŸtur
pipeline_cache = PipelineCache()

def duygu_analizi_demo(metin, dil="en"):
    """Duygu analizi pipeline demo fonksiyonu"""
    if not metin.strip():
        return "LÃ¼tfen bir metin girin!"
    
    try:
        # Model seÃ§imi
        if dil == "en":
            model = "distilbert-base-uncased-finetuned-sst-2-english"
        else:
            model = "nlptown/bert-base-multilingual-uncased-sentiment"
        
        # Ã–nbellekten pipeline al
        duygu_analizi = pipeline_cache.get_pipeline("sentiment-analysis", model=model)
        sonuc = duygu_analizi(metin)
        
        # SonuÃ§ sÄ±nÄ±fÄ±nÄ± belirle
        label = sonuc[0]["label"]
        score = sonuc[0]["score"]
        sentiment_class = "positive" if "POSITIVE" in label else "negative" if "NEGATIVE" in label else "neutral"
        
        # Daha basit HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header sentiment-{sentiment_class.lower()}">
                {label} (GÃ¼ven: {score:.4f})
            </div>
            <div class="result-content">
                <p>"{metin}"</p>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def metin_uretme_demo(baslangic_metni, max_uzunluk=50, tekrar_sayisi=1):
    """Metin Ã¼retme pipeline demo fonksiyonu"""
    if not baslangic_metni.strip():
        return "LÃ¼tfen bir baÅŸlangÄ±Ã§ metni girin!"
    
    try:
        # Ã–nbellekten pipeline al
        metin_uretici = pipeline_cache.get_pipeline("text-generation")
        sonuclar = metin_uretici(
            baslangic_metni, 
            max_length=max_uzunluk,
            num_return_sequences=tekrar_sayisi,
            do_sample=True
        )
        
        # Daha basit HTML Ã§Ä±ktÄ±sÄ±
        html_output = "<div>"
        for i, sonuc in enumerate(sonuclar, 1):
            html_output += f"<div class='result-card'><div class='result-content'><strong>SonuÃ§ {i}:</strong><p>{sonuc['generated_text']}</p></div></div>"
        html_output += "</div>"
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def maskeleme_demo(maskeli_metin):
    """Maskeleme pipeline demo fonksiyonu"""
    if not maskeli_metin.strip():
        return "LÃ¼tfen bir metin girin!"
    
    try:
        # Hangi mask token'Ä± kullanÄ±ldÄ±ÄŸÄ±nÄ± belirleyelim
        if "[MASK]" in maskeli_metin:
            mask_token = "[MASK]"
            model = "bert-base-uncased"
        elif "<mask>" in maskeli_metin:
            mask_token = "<mask>"
            model = "roberta-base"
        else:
            return "LÃ¼tfen maskelenmiÅŸ bir kelime ekleyin: [MASK] veya <mask>"
        
        # Ã–nbellekten pipeline al
        maskeleme = pipeline_cache.get_pipeline("fill-mask", model=model)
        sonuclar = maskeleme(maskeli_metin)
        
        # Daha basit HTML Ã§Ä±ktÄ±sÄ±
        html_output = "<div>"
        for i, sonuc in enumerate(sonuclar[:5], 1):
            html_output += f"<div class='result-card'><div class='result-content'><strong>{i}.</strong> {sonuc['sequence']}<br><small>Skor: {sonuc['score']:.4f}</small></div></div>"
        html_output += "</div>"
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def soru_cevaplama_demo(soru, metin):
    """Soru cevaplama pipeline demo fonksiyonu"""
    if not soru.strip() or not metin.strip():
        return "LÃ¼tfen hem soru hem de metin girin!"
    
    try:
        # Ã–nbellekten pipeline al
        soru_cevaplama = pipeline_cache.get_pipeline("question-answering")
        sonuc = soru_cevaplama(question=soru, context=metin)
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header sentiment-neutral">
                Cevap (GÃ¼ven: {sonuc['score']:.4f})
            </div>
            <div class="result-content">
                <p><strong>Soru:</strong> {soru}</p>
                <p><strong>Cevap:</strong> {sonuc['answer']}</p>
                <p><small>Metin iÃ§inde konum: {sonuc['start']} - {sonuc['end']}</small></p>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def ozetleme_demo(uzun_metin, max_uzunluk=150, min_uzunluk=50):
    """Metin Ã¶zetleme pipeline demo fonksiyonu"""
    if not uzun_metin.strip():
        return "LÃ¼tfen Ã¶zetlenecek bir metin girin!"
    
    try:
        # Ã–nbellekten pipeline al
        ozetleme = pipeline_cache.get_pipeline("summarization")
        ozet = ozetleme(
            uzun_metin, 
            max_length=max_uzunluk, 
            min_length=min_uzunluk, 
            do_sample=False
        )
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header sentiment-neutral">
                Ã–zet
            </div>
            <div class="result-content">
                <p>{ozet[0]['summary_text']}</p>
                <hr>
                <p><small><strong>Orijinal Metin UzunluÄŸu:</strong> {len(uzun_metin.split())} kelime</small></p>
                <p><small><strong>Ã–zet UzunluÄŸu:</strong> {len(ozet[0]['summary_text'].split())} kelime</small></p>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def ceviri_demo(text, source_lang, target_lang):
    """Ã‡eviri pipeline demo fonksiyonu"""
    if not text.strip():
        return "LÃ¼tfen Ã§evrilecek bir metin girin!"
    
    try:
        # Alternatif olarak daha yaygÄ±n kullanÄ±lan bir model kullanalÄ±m
        model_name = "facebook/m2m100_418M"  # Ã‡ok dilli Ã§eviri modeli
        
        # Ã–nbellekten model ve tokenizer'Ä± al
        pipeline_key = f"translation-{source_lang}-{target_lang}"
        if pipeline_key not in pipeline_cache.pipelines:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
            
            # M2M100 modeli iÃ§in Ã¶zel iÅŸlem
            from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer
            
            pipeline_cache.pipelines[f"{pipeline_key}-tokenizer"] = M2M100Tokenizer.from_pretrained(model_name)
            pipeline_cache.pipelines[f"{pipeline_key}-model"] = M2M100ForConditionalGeneration.from_pretrained(
                model_name,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None
            )
        
        tokenizer = pipeline_cache.pipelines[f"{pipeline_key}-tokenizer"]
        model = pipeline_cache.pipelines[f"{pipeline_key}-model"]
        
        # Dil kodlarÄ±nÄ± insan tarafÄ±ndan okunabilir formata dÃ¶nÃ¼ÅŸtÃ¼r
        source_lang_name = {
            "en": "Ä°ngilizce",
            "tr": "TÃ¼rkÃ§e",
            "fr": "FransÄ±zca",
            "de": "Almanca",
            "es": "Ä°spanyolca",
            "it": "Ä°talyanca",
            "ru": "RusÃ§a",
            "zh": "Ã‡ince",
            "ja": "Japonca",
            "ar": "ArapÃ§a",
            "pt": "Portekizce",
            "ko": "Korece"
        }.get(source_lang, source_lang)
        
        target_lang_name = {
            "en": "Ä°ngilizce",
            "tr": "TÃ¼rkÃ§e",
            "fr": "FransÄ±zca",
            "de": "Almanca",
            "es": "Ä°spanyolca",
            "it": "Ä°talyanca",
            "ru": "RusÃ§a",
            "zh": "Ã‡ince",
            "ja": "Japonca",
            "ar": "ArapÃ§a",
            "pt": "Portekizce",
            "ko": "Korece"
        }.get(target_lang, target_lang)
        
        # M2M100 modeli iÃ§in Ã§eviri iÅŸlemi
        # Kaynak dili ayarla
        tokenizer.src_lang = source_lang
        
        # Metni tokenize et
        encoded = tokenizer(text, return_tensors="pt")
        if torch.cuda.is_available():
            encoded = {k: v.to("cuda") for k, v in encoded.items()}
            model = model.to("cuda")
        
        # Ã‡eviriyi oluÅŸtur
        generated_tokens = model.generate(
            **encoded,
            forced_bos_token_id=tokenizer.get_lang_id(target_lang),
            max_length=512
        )
        
        # Ã‡eviriyi decode et
        translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header sentiment-neutral">
                Ã‡eviri Sonucu ({source_lang_name} â†’ {target_lang_name})
            </div>
            <div class="result-content">
                <div style="display: flex; flex-direction: column; gap: 15px;">
                    <div>
                        <p><strong>Kaynak Metin ({source_lang_name}):</strong></p>
                        <div style="background-color: #f8f9fa; padding: 10px; border-radius: 8px;">
                            {text}
                        </div>
                    </div>
                    <div>
                        <p><strong>Ã‡eviri ({target_lang_name}):</strong></p>
                        <div style="background-color: #f8f9fa; padding: 10px; border-radius: 8px;">
                            {translation}
                        </div>
                    </div>
                </div>
                <p><small><strong>Model:</strong> {model_name}</small></p>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        import traceback
        return f"Hata: {str(e)}<br><pre>{traceback.format_exc()}</pre>"

def ner_demo(metin):
    """VarlÄ±k Ä°smi TanÄ±ma (NER) pipeline demo fonksiyonu"""
    if not metin.strip():
        return "LÃ¼tfen bir metin girin!"
    
    try:
        # Ã–nbellekten pipeline al - grouped_entities parametresi ile
        ner = pipeline_cache.get_pipeline("ner", grouped_entities=True)
        sonuclar = ner(metin)
        
        # Renk sÄ±nÄ±flarÄ±
        entity_colors = {
            "PER": "sentiment-positive",  # KiÅŸi
            "ORG": "sentiment-negative",  # Organizasyon
            "LOC": "sentiment-neutral",   # Konum
            "MISC": "sentiment-neutral"   # DiÄŸer
        }
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = "<div>"
        for i, sonuc in enumerate(sonuclar, 1):
            entity_type = sonuc['entity_group']
            color_class = entity_colors.get(entity_type, "sentiment-neutral")
            
            html_output += f"""<div class="result-card">
                <div class="result-header {color_class}">
                    {entity_type} (GÃ¼ven: {sonuc['score']:.4f})
                </div>
                <div class="result-content">
                    <p><strong>Metin:</strong> {sonuc['word']}</p>
                    <p><small>Konum: {sonuc['start']} - {sonuc['end']}</small></p>
                </div>
            </div>"""
        
        if not sonuclar:
            html_output += "<p>Metinde tanÄ±mlanabilir varlÄ±k bulunamadÄ±.</p>"
        
        html_output += "</div>"
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def turkce_maskeleme_demo(maskeli_metin):
    """TÃ¼rkÃ§e maskeleme pipeline demo fonksiyonu"""
    if not maskeli_metin.strip():
        return "LÃ¼tfen bir metin girin!"
    
    try:
        # TÃ¼rkÃ§e BERT modeli
        model = "dbmdz/bert-base-turkish-cased"
        
        # Maske token'Ä± kontrol et
        if "[MASK]" not in maskeli_metin:
            return "LÃ¼tfen metinde en az bir [MASK] token'Ä± kullanÄ±n."
        
        # Ã–nbellekten pipeline al
        maskeleme = pipeline_cache.get_pipeline("fill-mask", model=model)
        sonuclar = maskeleme(maskeli_metin)
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = "<div>"
        for i, sonuc in enumerate(sonuclar[:5], 1):
            html_output += f"""<div class="result-card">
                <div class="result-content">
                    <strong>{i}.</strong> {sonuc['sequence']}
                    <br><small>Skor: {sonuc['score']:.4f}</small>
                </div>
            </div>"""
        
        html_output += "</div>"
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def metin_siniflandirma_demo(metin, kategori_sayisi=2):
    """Metin sÄ±nÄ±flandÄ±rma pipeline demo fonksiyonu"""
    if not metin.strip():
        return "LÃ¼tfen bir metin girin!"
    
    try:
        # Model seÃ§imi - kategori sayÄ±sÄ±na gÃ¶re
        if kategori_sayisi == 2:
            model = "distilbert-base-uncased-finetuned-sst-2-english"
        else:
            model = "j-hartmann/emotion-english-distilroberta-base"  # Ã‡ok sÄ±nÄ±flÄ± duygu analizi
        
        # Ã–nbellekten pipeline al
        siniflandirma = pipeline_cache.get_pipeline("text-classification", model=model)
        sonuclar = siniflandirma(metin)
        
        # Birden fazla sonuÃ§ varsa (top_k parametresi kullanÄ±ldÄ±ysa)
        if isinstance(sonuclar, list) and len(sonuclar) > 1:
            # HTML Ã§Ä±ktÄ±sÄ± - birden fazla sonuÃ§
            html_output = "<div>"
            for i, sonuc in enumerate(sonuclar, 1):
                label = sonuc['label']
                score = sonuc['score']
                
                # Renk sÄ±nÄ±fÄ± belirle
                if "POSITIVE" in label or "joy" in label or "love" in label:
                    color_class = "sentiment-positive"
                elif "NEGATIVE" in label or "anger" in label or "sadness" in label:
                    color_class = "sentiment-negative"
                else:
                    color_class = "sentiment-neutral"
                
                html_output += f"""<div class="result-card">
                    <div class="result-header {color_class}">
                        {label} (GÃ¼ven: {score:.4f})
                    </div>
                    <div class="result-content">
                        <p>SÄ±ralama: {i}</p>
                    </div>
                </div>"""
            
            html_output += "</div>"
        else:
            # Tek sonuÃ§
            sonuc = sonuclar[0] if isinstance(sonuclar, list) else sonuclar
            label = sonuc['label']
            score = sonuc['score']
            
            # Renk sÄ±nÄ±fÄ± belirle
            if "POSITIVE" in label or "joy" in label or "love" in label:
                color_class = "sentiment-positive"
            elif "NEGATIVE" in label or "anger" in label or "sadness" in label:
                color_class = "sentiment-negative"
            else:
                color_class = "sentiment-neutral"
            
            html_output = f"""<div class="result-card">
                <div class="result-header {color_class}">
                    {label} (GÃ¼ven: {score:.4f})
                </div>
                <div class="result-content">
                    <p>Metin: "{metin}"</p>
                    <p>Model: {model}</p>
                </div>
            </div>"""
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def sifir_atis_siniflandirma_demo(metin, etiketler):
    """SÄ±fÄ±r-atÄ±ÅŸ sÄ±nÄ±flandÄ±rma pipeline demo fonksiyonu"""
    if not metin.strip():
        return "LÃ¼tfen bir metin girin!"
    
    if not etiketler.strip():
        return "LÃ¼tfen sÄ±nÄ±flandÄ±rma etiketlerini girin!"
    
    try:
        # Etiketleri ayÄ±r
        etiket_listesi = [etiket.strip() for etiket in etiketler.split(",")]
        
        if len(etiket_listesi) < 2:
            return "LÃ¼tfen en az 2 etiket girin (virgÃ¼lle ayÄ±rarak)!"
        
        # Ã–nbellekten pipeline al
        zero_shot = pipeline_cache.get_pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
        sonuc = zero_shot(metin, etiket_listesi, multi_label=False)
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header sentiment-neutral">
                SÄ±fÄ±r-AtÄ±ÅŸ SÄ±nÄ±flandÄ±rma SonuÃ§larÄ±
            </div>
            <div class="result-content">
                <p><strong>Metin:</strong> {metin}</p>
                <p><strong>Etiketler:</strong> {', '.join(etiket_listesi)}</p>
                <hr>
                <p><strong>SonuÃ§lar:</strong></p>
                <ul>"""
        
        # Etiketleri ve skorlarÄ± listele
        for i, (etiket, skor) in enumerate(zip(sonuc['labels'], sonuc['scores']), 1):
            # Renk sÄ±nÄ±fÄ± belirle - en yÃ¼ksek skora sahip etiket iÃ§in farklÄ± renk
            color_class = "sentiment-positive" if i == 1 else ""
            html_output += f'<li class="{color_class}"><strong>{etiket}</strong>: {skor:.4f}</li>'
        
        html_output += """</ul>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def cumle_benzerligi_demo(cumle1, cumle2):
    """CÃ¼mle benzerliÄŸi demo fonksiyonu"""
    if not cumle1.strip() or not cumle2.strip():
        return "LÃ¼tfen her iki cÃ¼mleyi de girin!"
    
    try:
        # Sentence Transformers modelini yÃ¼kle
        model_name = "sentence-transformers/all-MiniLM-L6-v2"
        
        # Ã–nbellekten kontrol et veya yeni model oluÅŸtur
        if "sentence_transformer" not in pipeline_cache.pipelines:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
            pipeline_cache.pipelines["sentence_transformer"] = SentenceTransformer(model_name, device=f'cuda:{device}' if device >= 0 else 'cpu')
        
        model = pipeline_cache.pipelines["sentence_transformer"]
        
        # CÃ¼mleleri vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼r
        embedding1 = model.encode(cumle1, convert_to_tensor=True)
        embedding2 = model.encode(cumle2, convert_to_tensor=True)
        
        # KosinÃ¼s benzerliÄŸini hesapla
        cosine_similarity = util.pytorch_cos_sim(embedding1, embedding2).item()
        
        # Benzerlik yÃ¼zdesi
        similarity_percentage = (cosine_similarity + 1) / 2 * 100  # -1 ile 1 arasÄ±ndaki deÄŸeri 0-100 aralÄ±ÄŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
        
        # Benzerlik seviyesi
        if similarity_percentage >= 80:
            similarity_level = "Ã‡ok YÃ¼ksek"
            color_class = "sentiment-positive"
        elif similarity_percentage >= 60:
            similarity_level = "YÃ¼ksek"
            color_class = "sentiment-positive"
        elif similarity_percentage >= 40:
            similarity_level = "Orta"
            color_class = "sentiment-neutral"
        elif similarity_percentage >= 20:
            similarity_level = "DÃ¼ÅŸÃ¼k"
            color_class = "sentiment-negative"
        else:
            similarity_level = "Ã‡ok DÃ¼ÅŸÃ¼k"
            color_class = "sentiment-negative"
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header {color_class}">
                Benzerlik: {similarity_percentage:.2f}% ({similarity_level})
            </div>
            <div class="result-content">
                <p><strong>CÃ¼mle 1:</strong> {cumle1}</p>
                <p><strong>CÃ¼mle 2:</strong> {cumle2}</p>
                <p><strong>Model:</strong> {model_name}</p>
                <p><small>KosinÃ¼s BenzerliÄŸi: {cosine_similarity:.4f}</small></p>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def gorsel_soru_cevaplama_demo(image, soru):
    """GÃ¶rsel soru cevaplama demo fonksiyonu"""
    if image is None:
        return "LÃ¼tfen bir gÃ¶rÃ¼ntÃ¼ yÃ¼kleyin!"
    
    if not soru.strip():
        return "LÃ¼tfen bir soru girin!"
    
    try:
        # Model yÃ¼kle
        model_name = "nlpconnect/vit-gpt2-image-captioning"
        
        # Ã–nbellekten pipeline al
        image_to_text = pipeline_cache.get_pipeline("image-to-text", model=model_name)
        
        # GÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸle
        result = image_to_text(image)
        
        # GÃ¶rÃ¼ntÃ¼ aÃ§Ä±klamasÄ±
        image_caption = result[0]['generated_text']
        
        # Basit bir gÃ¶rsel QA simÃ¼lasyonu
        # Not: Bu gerÃ§ek bir VQA modeli deÄŸil, sadece gÃ¶rÃ¼ntÃ¼ aÃ§Ä±klamasÄ± ve soruyu birleÅŸtiriyor
        # GerÃ§ek bir VQA modeli iÃ§in daha karmaÅŸÄ±k bir yapÄ± gerekir
        
        # Soruyu analiz et
        soru_lower = soru.lower()
        cevap = "GÃ¶rÃ¼ntÃ¼yÃ¼ tam olarak analiz edemiyorum."
        
        # Basit soru-cevap mantÄ±ÄŸÄ±
        if "ne" in soru_lower or "nedir" in soru_lower:
            cevap = f"GÃ¶rÃ¼ntÃ¼de {image_caption.lower()} gÃ¶rÃ¼nÃ¼yor."
        elif "var mÄ±" in soru_lower:
            # Sorudaki anahtar kelimeleri kontrol et
            keywords = [word for word in soru_lower.split() if len(word) > 3 and word not in ["var", "mÄ±", "bir", "bu", "ÅŸu", "ve", "ile", "iÃ§in"]]
            found = any(keyword in image_caption.lower() for keyword in keywords)
            if found:
                cevap = f"Evet, gÃ¶rÃ¼ntÃ¼de {' veya '.join(k for k in keywords if k in image_caption.lower())} var."
            else:
                cevap = f"HayÄ±r, gÃ¶rÃ¼ntÃ¼de bahsettiÄŸiniz Ã¶ÄŸe gÃ¶rÃ¼nmÃ¼yor."
        elif "kaÃ§" in soru_lower:
            cevap = "GÃ¶rÃ¼ntÃ¼deki nesnelerin sayÄ±sÄ±nÄ± tam olarak belirleyemiyorum."
        elif "nerede" in soru_lower:
            cevap = "GÃ¶rÃ¼ntÃ¼nÃ¼n tam konumunu belirleyemiyorum."
        elif "kim" in soru_lower:
            if "person" in image_caption.lower() or "man" in image_caption.lower() or "woman" in image_caption.lower():
                cevap = "GÃ¶rÃ¼ntÃ¼de bir kiÅŸi var, ancak kim olduÄŸunu belirleyemiyorum."
            else:
                cevap = "GÃ¶rÃ¼ntÃ¼de bir kiÅŸi gÃ¶remiyorum."
        else:
            cevap = f"GÃ¶rÃ¼ntÃ¼ aÃ§Ä±klamasÄ±: {image_caption}"
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header sentiment-neutral">
                GÃ¶rsel Analiz Sonucu
            </div>
            <div class="result-content">
                <p><strong>Soru:</strong> {soru}</p>
                <p><strong>Cevap:</strong> {cevap}</p>
                <hr>
                <p><small><strong>GÃ¶rÃ¼ntÃ¼ AÃ§Ä±klamasÄ±:</strong> {image_caption}</small></p>
                <p><small><strong>Model:</strong> {model_name}</small></p>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def metin_duzeltme_demo(metin):
    """Metin dÃ¼zeltme pipeline demo fonksiyonu"""
    if not metin.strip():
        return "LÃ¼tfen dÃ¼zeltilecek bir metin girin!"
    
    try:
        # Model yÃ¼kle
        model_name = "oliverguhr/spelling-correction-english-base"
        
        # Ã–nbellekten pipeline al
        duzeltme = pipeline_cache.get_pipeline("text2text-generation", model=model_name)
        sonuc = duzeltme(metin, max_length=len(metin) + 50)
        
        duzeltilmis_metin = sonuc[0]['generated_text']
        
        # DeÄŸiÅŸiklikleri vurgula
        from difflib import SequenceMatcher
        
        def highlight_diff(a, b):
            matcher = SequenceMatcher(None, a, b)
            highlighted = ""
            for opcode, a0, a1, b0, b1 in matcher.get_opcodes():
                if opcode == 'equal':
                    highlighted += a[a0:a1]
                elif opcode == 'insert':
                    highlighted += f'<span style="background-color: #c8e6c9; font-weight: bold;">{b[b0:b1]}</span>'
                elif opcode == 'delete':
                    highlighted += f'<span style="background-color: #ffcdd2; text-decoration: line-through;">{a[a0:a1]}</span>'
                elif opcode == 'replace':
                    highlighted += f'<span style="background-color: #ffcdd2; text-decoration: line-through;">{a[a0:a1]}</span>'
                    highlighted += f'<span style="background-color: #c8e6c9; font-weight: bold;">{b[b0:b1]}</span>'
            return highlighted
        
        # DeÄŸiÅŸiklik var mÄ± kontrol et
        if metin == duzeltilmis_metin:
            degisiklik_mesaji = "Metinde dÃ¼zeltilecek bir hata bulunamadÄ±."
            vurgulu_metin = metin
        else:
            degisiklik_mesaji = "Metinde dÃ¼zeltmeler yapÄ±ldÄ±."
            vurgulu_metin = highlight_diff(metin, duzeltilmis_metin)
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header sentiment-neutral">
                Metin DÃ¼zeltme Sonucu
            </div>
            <div class="result-content">
                <p><strong>Orijinal Metin:</strong> {metin}</p>
                <p><strong>DÃ¼zeltilmiÅŸ Metin:</strong> {duzeltilmis_metin}</p>
                <hr>
                <p><strong>DeÄŸiÅŸiklikler:</strong> {degisiklik_mesaji}</p>
                <p>{vurgulu_metin}</p>
                <p><small><strong>Model:</strong> {model_name}</small></p>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def cok_sinifli_duygu_analizi_demo(metin):
    """Ã‡ok sÄ±nÄ±flÄ± duygu analizi pipeline demo fonksiyonu"""
    if not metin.strip():
        return "LÃ¼tfen bir metin girin!"
    
    try:
        # Model yÃ¼kle
        model_name = "j-hartmann/emotion-english-distilroberta-base"
        
        # Ã–nbellekten pipeline al
        duygu_analizi = pipeline_cache.get_pipeline("text-classification", model=model, top_k=None)
        sonuclar = duygu_analizi(metin)
        
        # Duygu renkleri
        duygu_renkleri = {
            "joy": "#4CAF50",      # YeÅŸil
            "love": "#E91E63",     # Pembe
            "anger": "#F44336",    # KÄ±rmÄ±zÄ±
            "fear": "#FF9800",     # Turuncu
            "sadness": "#2196F3",  # Mavi
            "surprise": "#9C27B0"  # Mor
        }
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header sentiment-neutral">
                Ã‡ok SÄ±nÄ±flÄ± Duygu Analizi
            </div>
            <div class="result-content">
                <p><strong>Metin:</strong> {metin}</p>
                <hr>
                <p><strong>Duygular:</strong></p>
                <div style="display: flex; flex-wrap: wrap; gap: 10px;">"""
        
        # Duygu Ã§ubuklarÄ±
        for sonuc in sonuclar[0]:
            duygu = sonuc['label']
            skor = sonuc['score']
            renk = duygu_renkleri.get(duygu, "#9E9E9E")  # VarsayÄ±lan gri
            
            html_output += f"""
                <div style="flex: 1; min-width: 150px;">
                    <div style="margin-bottom: 5px;"><strong>{duygu.capitalize()}</strong>: {skor:.4f}</div>
                    <div style="background-color: #f0f0f0; border-radius: 4px; height: 20px; width: 100%;">
                        <div style="background-color: {renk}; height: 100%; width: {skor * 100}%; border-radius: 4px;"></div>
                    </div>
                </div>"""
        
        html_output += """</div>
                <p><small><strong>Model:</strong> j-hartmann/emotion-english-distilroberta-base</small></p>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        return f"Hata: {str(e)}"

def konusma_tanima_demo(audio, dil):
    """KonuÅŸma tanÄ±ma pipeline demo fonksiyonu"""
    if audio is None:
        return "LÃ¼tfen bir ses dosyasÄ± yÃ¼kleyin!"
    
    try:
        # OpenAI Whisper modelini kullan
        model_name = "openai/whisper-large-v3-turbo"
        
        # Ã–nbellekten pipeline al
        pipeline_key = f"speech-recognition-{dil}"
        if pipeline_key not in pipeline_cache.pipelines:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
            pipeline_cache.pipelines[pipeline_key] = pipeline(
                "automatic-speech-recognition", 
                model=model_name,
                chunk_length_s=30,
                batch_size=16,
                device=device
            )
        
        konusma_tanima = pipeline_cache.pipelines[pipeline_key]
        
        # Dile gÃ¶re generate_kwargs ayarla
        generate_kwargs = {}
        if dil == "tr":
            generate_kwargs["language"] = "turkish"
        else:  # VarsayÄ±lan Ä°ngilizce
            generate_kwargs["language"] = "english"
        
        # Ses dosyasÄ±nÄ± iÅŸle
        sonuc = konusma_tanima(
            audio, 
            return_timestamps=True,
            generate_kwargs=generate_kwargs  # task ve language parametrelerini generate_kwargs iÃ§inde geÃ§ir
        )
        
        # Dil bilgisi
        dil_adi = "TÃ¼rkÃ§e" if dil == "tr" else "Ä°ngilizce"
        
        # Zaman damgalarÄ±nÄ± iÅŸle
        timestamps_html = ""
        if "chunks" in sonuc:
            timestamps_html = "<p><strong>Zaman DamgalarÄ±:</strong></p><ul>"
            for chunk in sonuc["chunks"]:
                start = chunk.get("timestamp", [0])[0]
                end = chunk.get("timestamp", [0, 0])[1]
                text = chunk.get("text", "")
                start_time = f"{int(start // 60)}:{int(start % 60):02d}"
                end_time = f"{int(end // 60)}:{int(end % 60):02d}"
                timestamps_html += f"<li><strong>{start_time} - {end_time}:</strong> {text}</li>"
            timestamps_html += "</ul>"
        
        # HTML Ã§Ä±ktÄ±sÄ±
        html_output = f"""<div class="result-card">
            <div class="result-header sentiment-neutral">
                KonuÅŸma TanÄ±ma Sonucu ({dil_adi})
            </div>
            <div class="result-content">
                <p><strong>Transkripsiyon:</strong> {sonuc["text"]}</p>
                {timestamps_html}
                <p><small><strong>Model:</strong> {model_name}</small></p>
            </div>
        </div>"""
        
        return html_output
    
    except Exception as e:
        import traceback
        return f"Hata: {str(e)}<br><pre>{traceback.format_exc()}</pre>"

# ArayÃ¼z oluÅŸturma
with gr.Blocks(title="Transformers Pipeline Demo", css=css, theme=theme) as demo:
    gr.Markdown("# ğŸ¤— Transformers Pipeline Demo")
    gr.Markdown("HuggingFace Transformers kÃ¼tÃ¼phanesi ile modern NLP uygulamalarÄ±")
    
    # GPU bilgisi
    if torch.cuda.is_available():
        gpu_info = f"ğŸš€ GPU: {torch.cuda.get_device_name(0)}"
    else:
        gpu_info = "âš ï¸ GPU bulunamadÄ±. Ä°ÅŸlemler CPU Ã¼zerinde Ã§alÄ±ÅŸacak."
    
    gr.Markdown(f"### {gpu_info}")
    
    with gr.Tabs():
        with gr.TabItem("ğŸ˜Š Duygu Analizi"):
            with gr.Row():
                with gr.Column():
                    dil = gr.Radio(
                        ["en", "tr"], 
                        label="Dil", 
                        value="en"
                    )
                    metin_input = gr.Textbox(
                        label="Metni Girin", 
                        placeholder="Analiz edilecek metni buraya yazÄ±n...",
                        value="I really enjoyed this movie, it was fantastic!",
                        lines=3
                    )
                    duygu_button = gr.Button("Duygu Analizi Yap", variant="primary")
                
                with gr.Column():
                    duygu_output = gr.HTML(label="SonuÃ§")
            
            duygu_button.click(
                duygu_analizi_demo, 
                inputs=[metin_input, dil], 
                outputs=duygu_output
            )
        
        with gr.TabItem("âœï¸ Metin Ãœretme"):
            with gr.Row():
                with gr.Column():
                    baslangic_input = gr.Textbox(
                        label="BaÅŸlangÄ±Ã§ Metni", 
                        placeholder="Metin Ã¼retmek iÃ§in baÅŸlangÄ±Ã§ metni girin...",
                        value="Artificial intelligence will",
                        lines=3
                    )
                    
                    with gr.Row():
                        max_uzunluk = gr.Slider(
                            minimum=10, maximum=100, value=50, 
                            label="Maksimum Uzunluk"
                        )
                        tekrar_sayisi = gr.Slider(
                            minimum=1, maximum=3, value=2, step=1,
                            label="Ãœretilecek Metin SayÄ±sÄ±"
                        )
                    
                    uretme_button = gr.Button("Metin Ãœret", variant="primary")
                
                with gr.Column():
                    uretilen_output = gr.HTML(label="Ãœretilen Metin")
            
            uretme_button.click(
                metin_uretme_demo, 
                inputs=[baslangic_input, max_uzunluk, tekrar_sayisi], 
                outputs=uretilen_output
            )
        
        with gr.TabItem("ğŸ­ Maskeleme"):
            with gr.Row():
                with gr.Column():
                    mask_input = gr.Textbox(
                        label="MaskelenmiÅŸ Metin", 
                        placeholder="Maskeli metni buraya yazÄ±n...",
                        value="HuggingFace is creating a <mask> that the community uses to solve NLP tasks.",
                        lines=3
                    )
                    mask_button = gr.Button("Maskeyi Doldur", variant="primary")
                
                with gr.Column():
                    mask_output = gr.HTML(label="SonuÃ§lar")
            
            mask_button.click(maskeleme_demo, inputs=mask_input, outputs=mask_output)
        
        with gr.TabItem("â“ Soru Cevaplama"):
            with gr.Row():
                with gr.Column():
                    soru_input = gr.Textbox(
                        label="Soru", 
                        placeholder="Sorunuzu buraya yazÄ±n...",
                        value="HuggingFace nedir?",
                        lines=2
                    )
                    metin_input = gr.Textbox(
                        label="Metin", 
                        placeholder="Sorunun cevaplanacaÄŸÄ± metni buraya yazÄ±n...",
                        value="HuggingFace, doÄŸal dil iÅŸleme alanÄ±nda kullanÄ±lan aÃ§Ä±k kaynaklÄ± kÃ¼tÃ¼phaneler ve modeller geliÅŸtiren bir ÅŸirkettir. Transformers kÃ¼tÃ¼phanesi ile tanÄ±nÄ±r ve yapay zeka topluluÄŸuna katkÄ±da bulunur.",
                        lines=6
                    )
                    soru_button = gr.Button("Soruyu Cevapla", variant="primary")
                
                with gr.Column():
                    soru_output = gr.HTML(label="Cevap")
            
            soru_button.click(
                soru_cevaplama_demo, 
                inputs=[soru_input, metin_input], 
                outputs=soru_output
            )

        with gr.TabItem("ğŸ“ Ã–zetleme"):
            with gr.Row():
                with gr.Column():
                    uzun_metin_input = gr.Textbox(
                        label="Uzun Metin", 
                        placeholder="Ã–zetlenecek metni buraya yazÄ±n...",
                        value="Yapay zeka (YZ), insan zekasÄ±nÄ± taklit eden ve topladÄ±klarÄ± bilgilere gÃ¶re yinelemeli olarak kendilerini iyileÅŸtirebilen sistemler veya makineler anlamÄ±na gelir. YZ, dar (veya zayÄ±f) YZ ve genel YZ olarak ikiye ayrÄ±lÄ±r. Dar YZ, belirli gÃ¶revleri yerine getirmek iÃ§in tasarlanmÄ±ÅŸtÄ±r ve gÃ¼nÃ¼mÃ¼zde yaygÄ±n olarak kullanÄ±lmaktadÄ±r. Genel YZ ise henÃ¼z tam olarak geliÅŸtirilmemiÅŸtir ve insan benzeri dÃ¼ÅŸÃ¼nme ve Ã¶ÄŸrenme yeteneÄŸine sahip olacaktÄ±r. YZ, doÄŸal dil iÅŸleme, bilgisayarlÄ± gÃ¶rÃ¼, robotik, makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenme gibi Ã§eÅŸitli alt alanlarÄ± iÃ§erir.",
                        lines=8
                    )
                    
                    with gr.Row():
                        min_uzunluk = gr.Slider(
                            minimum=10, maximum=100, value=30, 
                            label="Minimum Ã–zet UzunluÄŸu"
                        )
                        max_uzunluk = gr.Slider(
                            minimum=50, maximum=200, value=100, 
                            label="Maksimum Ã–zet UzunluÄŸu"
                        )
                    
                    ozet_button = gr.Button("Ã–zetle", variant="primary")
                
                with gr.Column():
                    ozet_output = gr.HTML(label="Ã–zet")
            
            ozet_button.click(
                ozetleme_demo, 
                inputs=[uzun_metin_input, max_uzunluk, min_uzunluk], 
                outputs=ozet_output
            )

        with gr.TabItem("ğŸŒ Ã‡eviri"):
            with gr.Row():
                with gr.Column():
                    ceviri_input = gr.Textbox(
                        label="Ã‡evrilecek Metin", 
                        placeholder="Ã‡evrilecek metni buraya yazÄ±n...",
                        value="HuggingFace is a company that provides tools for natural language processing.",
                        lines=3
                    )
                    
                    with gr.Row():
                        kaynak_dil = gr.Dropdown(
                            ["en", "fr", "de", "es"], 
                            label="Kaynak Dil", 
                            value="en"
                        )
                        hedef_dil = gr.Dropdown(
                            ["tr", "fr", "de", "es", "ru"], 
                            label="Hedef Dil", 
                            value="tr"
                        )
                    
                    ceviri_button = gr.Button("Ã‡evir", variant="primary")
                
                with gr.Column():
                    ceviri_output = gr.HTML(label="Ã‡eviri")
            
            ceviri_button.click(
                ceviri_demo, 
                inputs=[ceviri_input, kaynak_dil, hedef_dil], 
                outputs=ceviri_output
            )

        with gr.TabItem("ğŸ·ï¸ VarlÄ±k Ä°smi TanÄ±ma (NER)"):
            with gr.Row():
                with gr.Column():
                    ner_input = gr.Textbox(
                        label="Metin", 
                        placeholder="Metni buraya yazÄ±n...",
                        value="Apple Inc. is planning to open a new store in Istanbul, Turkiye next year. CEO Tim Cook announced this during his visit to Berlin, Germany.",
                        lines=3
                    )
                    ner_button = gr.Button("VarlÄ±klarÄ± TanÄ±", variant="primary")
                
                with gr.Column():
                    ner_output = gr.HTML(label="Bulunan VarlÄ±klar")
            
            ner_button.click(ner_demo, inputs=ner_input, outputs=ner_output)

        with gr.TabItem("ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Maskeleme"):
            with gr.Row():
                with gr.Column():
                    turkce_mask_input = gr.Textbox(
                        label="MaskelenmiÅŸ TÃ¼rkÃ§e Metin", 
                        placeholder="Maskeli metni buraya yazÄ±n...",
                        value="Yapay zeka [MASK] alanÄ±nda devrim yaratÄ±yor.",
                        lines=3
                    )
                    turkce_mask_button = gr.Button("Maskeyi Doldur", variant="primary")
                
                with gr.Column():
                    turkce_mask_output = gr.HTML(label="SonuÃ§lar")
            
            turkce_mask_button.click(turkce_maskeleme_demo, inputs=turkce_mask_input, outputs=turkce_mask_output)

        with gr.TabItem("ğŸ“‹ Metin SÄ±nÄ±flandÄ±rma"):
            with gr.Row():
                with gr.Column():
                    metin_input = gr.Textbox(
                        label="Metin", 
                        placeholder="Metin girin...",
                        value="I really enjoyed this movie, it was fantastic!",
                        lines=3
                    )
                    kategori_sayisi = gr.Slider(
                        minimum=2, maximum=5, value=2,
                        label="Kategori SayÄ±sÄ±"
                    )
                    siniflandirma_button = gr.Button("Metin SÄ±nÄ±flandÄ±r", variant="primary")
                
                with gr.Column():
                    siniflandirma_output = gr.HTML(label="SonuÃ§")
            
            siniflandirma_button.click(
                metin_siniflandirma_demo, 
                inputs=[metin_input, kategori_sayisi], 
                outputs=siniflandirma_output
            )

        with gr.TabItem("ğŸ“‹ SÄ±fÄ±r-AtÄ±ÅŸ SÄ±nÄ±flandÄ±rma"):
            with gr.Row():
                with gr.Column():
                    metin_input = gr.Textbox(
                        label="Metin", 
                        placeholder="Metin girin...",
                        value="I really enjoyed this movie, it was fantastic!",
                        lines=3
                    )
                    etiketler_input = gr.Textbox(
                        label="Etiketler", 
                        placeholder="Etiketleri virgÃ¼lle ayÄ±rarak girin...",
                        value="positive,negative,neutral",
                        lines=3
                    )
                    sifir_atis_button = gr.Button("SÄ±fÄ±r-AtÄ±ÅŸ SÄ±nÄ±flandÄ±r", variant="primary")
                
                with gr.Column():
                    sifir_atis_output = gr.HTML(label="SonuÃ§")
            
            sifir_atis_button.click(
                sifir_atis_siniflandirma_demo, 
                inputs=[metin_input, etiketler_input], 
                outputs=sifir_atis_output
            )

        with gr.TabItem("ğŸ”„ CÃ¼mle BenzerliÄŸi"):
            with gr.Row():
                with gr.Column():
                    cumle1_input = gr.Textbox(
                        label="CÃ¼mle 1", 
                        placeholder="Ä°lk cÃ¼mleyi buraya yazÄ±n...",
                        value="Yapay zeka, insan zekasÄ±nÄ± taklit eden sistemlerdir.",
                        lines=3
                    )
                    
                    cumle2_input = gr.Textbox(
                        label="CÃ¼mle 2", 
                        placeholder="Ä°kinci cÃ¼mleyi buraya yazÄ±n...",
                        value="AI, insan benzeri zeka gÃ¶steren bilgisayar sistemleridir.",
                        lines=3
                    )
                    
                    benzerlik_button = gr.Button("BenzerliÄŸi Hesapla", variant="primary")
                
                with gr.Column():
                    benzerlik_output = gr.HTML(label="Benzerlik Sonucu")
            
            benzerlik_button.click(
                cumle_benzerligi_demo, 
                inputs=[cumle1_input, cumle2_input], 
                outputs=benzerlik_output
            )

        with gr.TabItem("ğŸ–¼ï¸ GÃ¶rsel Soru Cevaplama"):
            with gr.Row():
                with gr.Column():
                    image_input = gr.Image(
                        label="GÃ¶rÃ¼ntÃ¼", 
                        type="pil",
                        sources=["upload", "clipboard"]
                    )
                    
                    soru_input = gr.Textbox(
                        label="Soru", 
                        placeholder="GÃ¶rÃ¼ntÃ¼ hakkÄ±nda bir soru sorun...",
                        value="Bu gÃ¶rÃ¼ntÃ¼de ne var?",
                        lines=2
                    )
                    
                    gorsel_button = gr.Button("Soruyu Cevapla", variant="primary")
                
                with gr.Column():
                    gorsel_output = gr.HTML(label="Cevap")
            
            gorsel_button.click(
                gorsel_soru_cevaplama_demo, 
                inputs=[image_input, soru_input], 
                outputs=gorsel_output
            )

        with gr.TabItem("ğŸ“ Metin DÃ¼zeltme"):
            with gr.Row():
                with gr.Column():
                    duzeltme_input = gr.Textbox(
                        label="DÃ¼zeltilecek Metin", 
                        placeholder="DÃ¼zeltilecek metni buraya yazÄ±n...",
                        value="I havv a problm with my computr. It dosnt work proprly.",
                        lines=3
                    )
                    duzeltme_button = gr.Button("Metni DÃ¼zelt", variant="primary")
                
                with gr.Column():
                    duzeltme_output = gr.HTML(label="DÃ¼zeltilmiÅŸ Metin")
            
            duzeltme_button.click(
                metin_duzeltme_demo, 
                inputs=duzeltme_input, 
                outputs=duzeltme_output
            )

        with gr.TabItem("ğŸ˜Š Ã‡ok SÄ±nÄ±flÄ± Duygu Analizi"):
            with gr.Row():
                with gr.Column():
                    cok_duygu_input = gr.Textbox(
                        label="Metin", 
                        placeholder="Analiz edilecek metni buraya yazÄ±n...",
                        value="I'm so happy to see you again! It's been a long time and I missed you so much.",
                        lines=3
                    )
                    cok_duygu_button = gr.Button("DuygularÄ± Analiz Et", variant="primary")
                
                with gr.Column():
                    cok_duygu_output = gr.HTML(label="Duygu Analizi Sonucu")
            
            cok_duygu_button.click(
                cok_sinifli_duygu_analizi_demo, 
                inputs=cok_duygu_input, 
                outputs=cok_duygu_output
            )

        with gr.TabItem("ğŸ¤ KonuÅŸma TanÄ±ma"):
            with gr.Row():
                with gr.Column():
                    audio_input = gr.Audio(
                        label="Ses DosyasÄ±", 
                        type="filepath",
                        sources=["upload", "microphone"]
                    )
                    
                    konusma_dil = gr.Radio(
                        choices=["en", "tr"], 
                        label="KonuÅŸma Dili", 
                        value="tr",  # VarsayÄ±lan olarak TÃ¼rkÃ§e seÃ§ili
                        info="en: Ä°ngilizce, tr: TÃ¼rkÃ§e"
                    )
                    
                    konusma_button = gr.Button("KonuÅŸmayÄ± TanÄ±", variant="primary")
                
                with gr.Column():
                    konusma_output = gr.HTML(label="Transkripsiyon")
            
            konusma_button.click(
                fn=konusma_tanima_demo, 
                inputs=[audio_input, konusma_dil], 
                outputs=konusma_output
            )
    
    # Basit footer
    gr.Markdown("---\n*ğŸ¤— Transformers Pipeline Demo | Hugging Face TÃ¼rkÃ§e EÄŸitim*")

# Demo'yu Ã§alÄ±ÅŸtÄ±r
if __name__ == "__main__":
    demo.launch(share=True) 